defaults:
  - _self_
  - override hydra/hydra_logging: disabled
  - override hydra/job_logging: disabled

seed: 1413
prob:
  name: indepset
  prefix: ind
  n_objs: 3
  n_vars: 100
  attach: 4
  seed: 7

size:

# Distributed training
distributed: false
env: local
dist_backend: nccl
init_method: tcp://127.0.0.1:3456

# Training config
# scratch | last_checkpoint
training_from: scratch
logging: 2
# Epochs after which to validate the model
validate_every: 1
validate_on_master: true
# Epochs after which to save the model
save_every: 1
# Set this to a positive number when using GPU
n_worker_dataloader: 1
# Checkpoint directory with timestamp
with_timestamp: false
wandb_log: false

# Dataset config
dataset:
  train:
    from_pid: 0
    to_pid: 10
    # Fraction of samples to use per training epoch in range (0, 1]
    frac_per_epoch: 1
  val:
    from_pid: 1000
    to_pid: 1010
  test:
    from_pid: 1100
    to_pid: 1200
  # Dataset used for validation
  # val | train
  # When set to train, we will randomly subsample 10% of training dataset
  # for validation. This is used as a sanity check.
  validate_on: val
  # Fraction of the training dataset used for validation
  # This will only be used when validate_on == train
  validate_on_frac: 0.1
  # Save parents of nodes in the dataset
  with_parent: false
  # Number of negative samples per one positive sample
  neg_to_pos_ratio: 1
  layer_weight: exponential

# Optimization config
epochs: 3
batch_size: 100
opt:
  name: Adam
  lr: 1e-3
  wd: 1e-4
clip_grad: 1.0
norm_type: 2.0
agg: sum            # cat | sum

# Model config
# transformer | gat
encoder_type: transformer
n_node_feat: 2
n_edge_type: 2
d_emb: 64
top_k: 5
n_blocks: 2
n_heads: 8
dropout_token: 0
dropout: 0.2
bias_mha: false
bias_mlp: false
h2i_ratio: 2


eval:
  # learning | downstream
  task: learning
  # learning: train | val
  # downstream: train | val | test
  split: val
  # Select all nodes upto layer
  select_all: 1
  # Method used for stitching
  # parent: Select all nodes with a high-scoring parent
  # min_resistance: Minimize local resistance based on lookahead
  # mip: Minimize global resistance using MIP
  stitch: parent
  # To be used with min resistance
  lookahead: 1

# Problem
problem_type: 2
# Is problem is maximization form
maximization: true
# Graph type for Set Packing/Independent Set problem
graph_type: stidsen

hydra:
  output_subdir: null
  run:
    dir: .
